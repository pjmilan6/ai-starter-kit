synthetic:
  model_names: 
    - 'DeepSeek-R1'
    - 'DeepSeek-R1-Distill-Llama-70B'
    - 'QwQ-32B'
    - 'Llama-3.1-Swallow-70B-Instruct-v0.3'
    - 'Llama-3.1-Swallow-8B-Instruct-v0.3'
    - 'Llama-3.1-Tulu-3-405B'
    - 'Meta-Llama-3.1-405B-Instruct'
    - 'Meta-Llama-3.1-70B-Instruct'
    - 'Meta-Llama-3.1-8B-Instruct'
    - 'Meta-Llama-3.2-1B-Instruct'
    - 'Meta-Llama-3.2-3B-Instruct'
    - 'Meta-Llama-3.3-70B-Instruct'
    - 'Qwen2.5-72B-Instruct'
    - 'Qwen2.5-Coder-32B-Instruct'
  llm_api: 'sncloud'
  results_dir: '~/github_repos/benchmarking_tracking_tests/logs/output_files'
  consolidated_results_dir: '~/github_repos/benchmarking_tracking_tests/consolidated_results'
  timeout: 3600
  time_delay: 0
  ratio: 1
  
  input_tokens:
    - 128
    - 128
    - 128
    - 128
    - 128
    - 128
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 128
    - 128
    - 128
    - 128
    - 128
    - 128
    - 2048
    - 2048
    - 2048
    - 2048
    - 2048
    - 2048
    - 2000
    - 2000
    - 2000
    - 2000
    - 2000
    - 2000
  output_tokens:
    - 128
    - 128
    - 128
    - 128
    - 128
    - 128
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 2048
    - 2048
    - 2048
    - 2048
    - 2048
    - 2048
    - 128
    - 128
    - 128
    - 128
    - 128
    - 128
    - 2000
    - 2000
    - 2000
    - 2000
    - 2000
    - 2000
  concurrent_requests:
    - 1
    - 2
    - 4
    - 8
    - 16
    - 32
    - 1
    - 2
    - 4
    - 8
    - 16
    - 32
    - 1
    - 2
    - 4
    - 8
    - 16
    - 32
    - 1
    - 2
    - 4
    - 8
    - 16
    - 32
    - 1
    - 2
    - 4
    - 8
    - 16
    - 32
